{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries"
      ],
      "metadata": {
        "id": "8zc5Qp5s8eQ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10VqEhMLiUZC",
        "outputId": "b048e4ef-a950-4075-da01-dda4068c7f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m92.2/111.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install ijson --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U sentence-transformers --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O10SAIZ8nAZg",
        "outputId": "eae5d878-7b53-497c-8af2-bc568ff65b5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/86.0 kB\u001b[0m \u001b[31m840.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPjDAC6wiZNi",
        "outputId": "21384ea5-4a80-4432-90d6-c295c4d8f904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mount the google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2r2XsRoDtrrT"
      },
      "outputs": [],
      "source": [
        "#import required libraries\n",
        "\n",
        "import ijson\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5hYLoexvNL0m"
      },
      "outputs": [],
      "source": [
        "#base path where all project files are stored\n",
        "\n",
        "base_path = \"drive/MyDrive/CS646\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KOYenFGMt1MP"
      },
      "outputs": [],
      "source": [
        "#analysing training data\n",
        "\n",
        "training_data_users = {}\n",
        "training_data_user_ids = []\n",
        "count = 0\n",
        "\n",
        "with open(base_path + '/train_questions.json', 'r') as file:\n",
        "  parser = ijson.items(file, 'item')\n",
        "  for item in parser:\n",
        "    user_id = item.get('id')\n",
        "    user_profile = item.get('profile')\n",
        "    num_profiles = len(user_profile)\n",
        "\n",
        "    training_data_users[user_id] = num_profiles\n",
        "    training_data_user_ids.append(user_id)\n",
        "\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "v9k6G_vRN3CN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133ca992-eb3e-4efb-8fac-6772fbee2989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data statistics\n",
            "length of training data:  20000\n",
            "max number of profiles for a user:  1028\n",
            "min number of profiles for a user:  99\n"
          ]
        }
      ],
      "source": [
        "print(\"training data statistics\")\n",
        "print(\"length of training data: \", count)\n",
        "print(\"max number of profiles for a user: \", max(val for key,val in training_data_users.items()))\n",
        "print(\"min number of profiles for a user: \", min(val for key,val in training_data_users.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_vM2omQ-LR1W"
      },
      "outputs": [],
      "source": [
        "#analysing test data\n",
        "\n",
        "test_data_users = {}\n",
        "test_data_user_ids = []\n",
        "count = 0\n",
        "\n",
        "with open(base_path + '/test_questions.json', 'r') as file:\n",
        "  parser = ijson.items(file, 'item')\n",
        "  for item in parser:\n",
        "    user_id = item.get('id')\n",
        "    user_profile = item.get('profile')\n",
        "    num_profiles = len(user_profile)\n",
        "\n",
        "    test_data_users[user_id] = num_profiles\n",
        "    test_data_user_ids.append(user_id)\n",
        "\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test data statistics\")\n",
        "print(\"length of test data: \", count)\n",
        "print(\"max number of profiles for a user: \", max(val for key,val in test_data_users.items()))\n",
        "print(\"min number of profiles for a user: \", min(val for key,val in test_data_users.items()))"
      ],
      "metadata": {
        "id": "2xgerhf3ndVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ea24cf-99f4-48cc-e241-da59ab67a735"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test data statistics\n",
            "length of test data:  2500\n",
            "max number of profiles for a user:  1006\n",
            "min number of profiles for a user:  99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#analysing validation data\n",
        "\n",
        "val_data_users = {}\n",
        "val_data_user_ids = []\n",
        "count = 0\n",
        "\n",
        "with open(base_path + '/dev_questions.json', 'r') as file:\n",
        "  parser = ijson.items(file, 'item')\n",
        "  for item in parser:\n",
        "    user_id = item.get('id')\n",
        "    user_profile = item.get('profile')\n",
        "    num_profiles = len(user_profile)\n",
        "\n",
        "    val_data_users[user_id] = num_profiles\n",
        "    val_data_user_ids.append(user_id)\n",
        "\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "8coZeWUkQsee"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"val data statistics\")\n",
        "print(\"length of val data: \", count)\n",
        "print(\"max number of profiles for a user: \", max(val for key,val in val_data_users.items()))\n",
        "print(\"min number of profiles for a user: \", min(val for key,val in val_data_users.items()))"
      ],
      "metadata": {
        "id": "SktYik1SQuM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8049286-5b75-4f5b-e7fd-3e696fecad9e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val data statistics\n",
            "length of val data:  2500\n",
            "max number of profiles for a user:  1023\n",
            "min number of profiles for a user:  99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assert that there is nothing common between training, test and validation data"
      ],
      "metadata": {
        "id": "_MsiL7xj9Ibo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(set(training_data_user_ids) & set(test_data_user_ids))"
      ],
      "metadata": {
        "id": "9bcDsZi6ngNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3684b001-e4b8-40f2-9da2-89b7e75bb034"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(set(val_data_user_ids) & set(test_data_user_ids))"
      ],
      "metadata": {
        "id": "vfBIE-X6SFMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb67141-6c4a-4336-e3cb-88e5e9c171f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(set(val_data_user_ids) & set(training_data_user_ids))"
      ],
      "metadata": {
        "id": "dfexveYDSK9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3beb356f-46f2-4a07-ff29-f208edc9acf7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This functions creates clusters for a given user profile. It puts reviews with same rating in a single cluster\n",
        "\n",
        "def get_clusters_for_user(user_profiles):\n",
        "    clusters = {}\n",
        "    clusters['1'] = []\n",
        "    clusters['2'] = []\n",
        "    clusters['3'] = []\n",
        "    clusters['4'] = []\n",
        "    clusters['5'] = []\n",
        "\n",
        "    for profile in user_profiles:\n",
        "        text = profile.get('text')\n",
        "        score = profile.get('score')\n",
        "        clusters[score].append(text)\n",
        "\n",
        "    return clusters"
      ],
      "metadata": {
        "id": "tJ1i--loniAn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initiate the model used for getting embeddings\n",
        "\n",
        "%%capture\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "MXH4tKxsnmBs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#method to get the scores for each cluster\n",
        "\n",
        "def get_scores_for_clusters(test_review, clusters):\n",
        "    scores = []\n",
        "    top_reviews = []\n",
        "    for score in ('1', '2', '3', '4', '5'):\n",
        "        reviews = clusters.get(score)\n",
        "        # print(\"total score \" + score + \" reviews \", len(reviews))\n",
        "\n",
        "        cluster_score = 0\n",
        "        count = 0\n",
        "        highest_score = 0\n",
        "        top_review = \"\"\n",
        "\n",
        "        test_review_embedding = model.encode([test_review])\n",
        "\n",
        "        for review in reviews:\n",
        "            review_embedding = model.encode([review])\n",
        "            score = util.pytorch_cos_sim(review_embedding, test_review_embedding).item()\n",
        "            cluster_score += score\n",
        "            count += 1\n",
        "\n",
        "            if highest_score < score:\n",
        "                highest_score = score\n",
        "                top_review = review\n",
        "            if count>=200:\n",
        "                break\n",
        "\n",
        "        if count > 0:\n",
        "            cluster_avg_score = cluster_score/count\n",
        "        else:\n",
        "            cluster_avg_score = 0\n",
        "\n",
        "        scores.append(cluster_avg_score)\n",
        "        top_reviews.append(top_review)\n",
        "\n",
        "    return scores, top_reviews\n"
      ],
      "metadata": {
        "id": "kusydApNnpCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVcRvOyROdgd"
      },
      "outputs": [],
      "source": [
        "# get review with highest score in a given cluster\n",
        "\n",
        "def get_top_review_in_cluster(test_review, reviews):\n",
        "  test_review_embedding = model.encode([test_review])\n",
        "  max_score = 0\n",
        "  top_score_review = \"\"\n",
        "\n",
        "  for review in reviews:\n",
        "      review_embedding = model.encode([review])\n",
        "      score = util.pytorch_cos_sim(review_embedding, test_review_embedding).item()\n",
        "      if max_score < score:\n",
        "        max_score = score\n",
        "        top_score_review = review\n",
        "\n",
        "  return top_score_review"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get k reviews by fetching 1 top review from each of k clusters\n",
        "\n",
        "def get_top_k_reviews(clusters_scores, top_reviews, k):\n",
        "  top_k_reviews = {}\n",
        "  sorted_indices = np.argsort(clusters_scores)[::-1]\n",
        "\n",
        "  for i in range(k):\n",
        "    if clusters_scores[sorted_indices[i]] != 0:\n",
        "      score = str(sorted_indices[i]+1)\n",
        "      review = top_reviews[sorted_indices[i]]\n",
        "      top_k_reviews[score] = review\n",
        "\n",
        "  return top_k_reviews"
      ],
      "metadata": {
        "id": "IvHBcRevptq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# method to generate the prompt for LLM\n",
        "\n",
        "def generate_llm_input(input, top_k_reviews):\n",
        "  prompt = \"\"\n",
        "  for score,review in top_k_reviews.items():\n",
        "    prompt += score + \" is the score for \" + '\"' + review + '\"' + \", and \"\n",
        "\n",
        "  prompt = prompt[:-6]\n",
        "  prompt += input\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "z1iF7s5ilWdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get language model score for the given input review and existing relevant reviews\n",
        "\n",
        "def get_language_model_score(input, top_k_reviews):\n",
        "  model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "\n",
        "  prompt = generate_llm_input(input, top_k_reviews)\n",
        "  # print(\"prompt is :\" + prompt)\n",
        "\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "  outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "  rating = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "  return rating"
      ],
      "metadata": {
        "id": "bQxwR12Zptoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to run the model on test data and generate the outputs\n",
        "\n",
        "test_ratings = {}\n",
        "\n",
        "def test():\n",
        "    count = 0\n",
        "    with open(base_path + '/test_questions.json', 'r') as file:\n",
        "        parser = ijson.items(file, 'item')\n",
        "        for item in parser:\n",
        "            user_id = item.get('id')\n",
        "            user_profiles = item.get('profile')\n",
        "            input = item.get('input')\n",
        "\n",
        "            clusters = get_clusters_for_user(user_profiles)\n",
        "\n",
        "            test_review = input.split(':')[1].strip()\n",
        "\n",
        "            clusters_scores, top_reviews = get_scores_for_clusters(test_review, clusters)\n",
        "\n",
        "            top_k_reviews = get_top_k_reviews(clusters_scores, top_reviews, 3)\n",
        "\n",
        "            rating = get_language_model_score(input, top_k_reviews)\n",
        "\n",
        "            test_ratings[user_id] = rating[0]\n",
        "            print(\"rating is \" + rating[0])\n"
      ],
      "metadata": {
        "id": "SpBQcTCUpt03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calling test function to get the outputs of test dataset. Storing in a csv file\n",
        "\n",
        "# test()\n",
        "# df = pd.DataFrame(test_ratings.items(), columns=['id', 'rating'])\n",
        "# df.to_csv(base_path + '/test_ratings.csv')"
      ],
      "metadata": {
        "id": "RQuXanUNptmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to run the model on validation data and generate the outputs.\n",
        "# this method is different from the test function above as it predicts the outputs in batches\n",
        "\n",
        "def val(start_index, end_index):\n",
        "    val_ratings = {}\n",
        "    count = 0\n",
        "    iterated = 0\n",
        "    invalid_ratings = 0\n",
        "    with open(base_path + '/dev_questions.json', 'r') as file:\n",
        "        parser = ijson.items(file, 'item')\n",
        "        for item in parser:\n",
        "            count += 1\n",
        "            if count<start_index or count>end_index:\n",
        "                continue\n",
        "            user_id = item.get('id')\n",
        "            user_profiles = item.get('profile')\n",
        "            input = item.get('input')\n",
        "\n",
        "            clusters = get_clusters_for_user(user_profiles)\n",
        "\n",
        "            test_review = input.split(':')[1].strip()\n",
        "\n",
        "            clusters_scores, top_reviews = get_scores_for_clusters(test_review, clusters)\n",
        "\n",
        "            top_k_reviews = get_top_k_reviews(clusters_scores, top_reviews, 2)\n",
        "\n",
        "            rating = get_language_model_score(input, top_k_reviews)\n",
        "            rating = rating[0]\n",
        "            if rating not in ('1', '2', '3', '4', '5'):\n",
        "                rating = 5\n",
        "                invalid_ratings += 1\n",
        "\n",
        "            val_ratings[user_id] = rating\n",
        "\n",
        "            iterated += 1\n",
        "            if iterated%10 == 0:\n",
        "                print(\"iterated: \" + str(iterated))\n",
        "\n",
        "    return val_ratings\n"
      ],
      "metadata": {
        "id": "PzVYh_QhbHtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#running in multiple batches one by one due to resource constraint\n",
        "\n",
        "#batch1(1,400)\n",
        "#val_ratings = val(1,400)\n",
        "\n",
        "#batch1(401,800)\n",
        "#val_ratings = val(401,800)\n",
        "\n",
        "#batch1(801,1200)\n",
        "#val_ratings = val(801,1200)\n",
        "\n",
        "#batch1(1201,1600)\n",
        "#val_ratings = val(1201,1600)\n",
        "\n",
        "#batch1(1601,2000)\n",
        "#val_ratings = val(1601,2000)\n",
        "\n",
        "#batch1(2001,2500)\n",
        "#val_ratings = val(2001,2500)"
      ],
      "metadata": {
        "id": "lyjc2RccSyZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for each of the batches, storing the predictions obtained in a csv file\n",
        "\n",
        "df = pd.DataFrame(val_ratings.items(), columns=['id', 'rating'])\n",
        "df.tail(10)\n",
        "df.to_csv(base_path + '/val_ratings_batch_5_1601_2000.csv')"
      ],
      "metadata": {
        "id": "FWWGGmJ3Pnoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uT5mfGwmFFgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric evaluation part"
      ],
      "metadata": {
        "id": "wbhV2F8ZFm7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the predictions stored in multiple csv files. The predicted ratings are stored in y_predicted\n",
        "\n",
        "y_predicted = []\n",
        "\n",
        "filenames = ['val_ratings_batch_1_1_400.csv', 'val_ratings_batch_2_401_800.csv', 'val_ratings_batch_3_801_1200.csv', 'val_ratings_batch_4_1201_1600.csv', 'val_ratings_batch_5_1601_2000.csv',\n",
        "             'val_ratings_batch_6_2001_2500.csv']\n",
        "\n",
        "for filename in filenames:\n",
        "    filepath = base_path + '/' + filename\n",
        "    with open(filepath, 'r') as f:\n",
        "        count = 0\n",
        "        for line in f:\n",
        "            if count != 0:\n",
        "                y_predicted.append(int(line.split(',')[2]))\n",
        "            count += 1\n"
      ],
      "metadata": {
        "id": "rJyTZ-IRVOMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assert that length of predicted values is 2500 (length of validation data)\n",
        "\n",
        "len(y_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDOVlbTnVTux",
        "outputId": "12be0352-ce86-4318-ab67-737457ac2aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the ground truth values from the json file. The ground truth ratings are stored in y_actual\n",
        "\n",
        "import json\n",
        "\n",
        "y_actual = []\n",
        "with open(base_path + '/dev_outputs.json') as f:\n",
        "    d = json.load(f)\n",
        "    golds = d.get('golds')\n",
        "    for gold in golds:\n",
        "        y_actual.append(int(gold.get('output')))\n",
        "    print(\"y_actual \", y_actual)\n"
      ],
      "metadata": {
        "id": "NWC3WL6Jnzo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e924302f-bb7a-4fb4-dfba-d60a96c03c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_actual  [2, 5, 5, 1, 5, 3, 4, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 3, 5, 4, 5, 5, 4, 5, 4, 2, 3, 5, 2, 4, 5, 4, 3, 5, 5, 5, 5, 5, 4, 4, 1, 5, 5, 4, 5, 4, 5, 4, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 4, 5, 4, 1, 4, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 5, 5, 1, 5, 3, 3, 4, 5, 4, 4, 3, 4, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5, 5, 4, 5, 4, 2, 5, 5, 4, 5, 4, 5, 5, 5, 4, 5, 4, 5, 3, 4, 3, 3, 5, 5, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 3, 4, 4, 5, 5, 3, 5, 4, 5, 5, 4, 5, 5, 5, 5, 5, 5, 3, 1, 5, 5, 5, 1, 5, 5, 5, 4, 4, 3, 5, 5, 4, 4, 1, 4, 3, 5, 3, 2, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 3, 5, 4, 2, 4, 4, 4, 1, 5, 5, 5, 4, 5, 4, 5, 5, 2, 5, 3, 4, 5, 5, 4, 5, 3, 5, 5, 1, 2, 5, 4, 3, 5, 2, 5, 2, 5, 5, 5, 4, 4, 4, 5, 4, 5, 5, 5, 5, 5, 2, 5, 5, 4, 5, 4, 5, 5, 4, 5, 5, 5, 4, 5, 4, 4, 5, 5, 1, 5, 4, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5, 4, 5, 4, 5, 5, 5, 3, 4, 4, 3, 4, 5, 4, 5, 5, 5, 1, 5, 1, 4, 3, 5, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 2, 5, 4, 5, 5, 5, 1, 5, 5, 5, 5, 1, 5, 5, 5, 4, 5, 5, 5, 5, 3, 5, 4, 1, 3, 4, 4, 5, 3, 5, 5, 5, 1, 5, 4, 5, 4, 4, 5, 2, 3, 4, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 2, 4, 4, 5, 5, 5, 4, 5, 5, 4, 4, 1, 4, 4, 5, 5, 4, 3, 5, 3, 5, 5, 5, 5, 5, 4, 3, 2, 5, 4, 2, 5, 5, 5, 2, 4, 4, 5, 2, 5, 5, 5, 4, 5, 4, 5, 5, 5, 5, 3, 4, 5, 5, 5, 3, 2, 4, 4, 5, 4, 4, 5, 5, 5, 4, 5, 4, 5, 4, 5, 5, 5, 5, 4, 5, 5, 3, 2, 5, 5, 5, 3, 5, 4, 4, 5, 3, 4, 5, 5, 5, 5, 4, 5, 5, 3, 4, 5, 5, 5, 5, 5, 4, 3, 5, 5, 5, 5, 1, 4, 5, 5, 5, 3, 5, 2, 3, 2, 5, 2, 5, 2, 4, 5, 5, 5, 5, 4, 1, 5, 5, 5, 3, 3, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 3, 5, 5, 2, 5, 5, 5, 5, 4, 5, 3, 4, 5, 1, 5, 4, 5, 4, 4, 4, 4, 5, 4, 4, 5, 5, 5, 5, 5, 5, 4, 5, 5, 3, 4, 3, 4, 5, 5, 5, 3, 5, 4, 5, 4, 3, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 3, 5, 5, 2, 2, 5, 5, 4, 2, 4, 4, 5, 3, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 2, 5, 5, 5, 4, 5, 4, 4, 5, 4, 4, 1, 5, 5, 5, 4, 5, 5, 5, 4, 4, 4, 5, 5, 5, 5, 4, 2, 4, 2, 1, 2, 5, 3, 4, 5, 4, 5, 5, 5, 4, 5, 2, 4, 2, 5, 5, 5, 5, 4, 3, 4, 5, 5, 2, 4, 4, 5, 4, 5, 4, 5, 5, 4, 5, 4, 5, 4, 1, 5, 5, 4, 3, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 2, 5, 4, 5, 3, 3, 5, 5, 5, 5, 3, 4, 5, 4, 3, 5, 5, 5, 5, 4, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 5, 5, 1, 3, 5, 5, 5, 5, 3, 5, 1, 4, 5, 5, 5, 3, 2, 5, 5, 5, 3, 2, 4, 4, 5, 1, 5, 3, 5, 4, 5, 5, 4, 5, 5, 5, 3, 4, 3, 5, 1, 5, 4, 4, 5, 5, 5, 3, 4, 5, 2, 5, 5, 5, 5, 5, 5, 5, 1, 5, 4, 5, 5, 4, 5, 4, 5, 5, 5, 5, 4, 2, 5, 4, 4, 3, 5, 1, 5, 4, 4, 5, 1, 5, 5, 5, 5, 5, 4, 5, 5, 3, 4, 5, 5, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 2, 5, 5, 5, 4, 5, 5, 1, 5, 4, 5, 5, 5, 5, 4, 4, 2, 4, 5, 4, 5, 5, 1, 5, 3, 4, 3, 1, 5, 5, 4, 5, 4, 5, 5, 4, 4, 5, 4, 4, 4, 5, 5, 5, 5, 5, 2, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 4, 5, 2, 4, 5, 5, 5, 4, 1, 3, 5, 5, 4, 2, 5, 5, 4, 5, 4, 5, 5, 4, 4, 4, 1, 5, 5, 3, 4, 5, 4, 4, 5, 5, 5, 5, 1, 4, 5, 4, 5, 5, 4, 5, 4, 5, 3, 5, 2, 5, 4, 4, 5, 5, 4, 5, 5, 5, 4, 5, 4, 1, 4, 5, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 5, 4, 5, 5, 1, 5, 4, 5, 2, 5, 3, 1, 3, 5, 4, 5, 5, 3, 2, 2, 5, 5, 5, 5, 1, 4, 5, 4, 4, 5, 5, 5, 1, 5, 3, 4, 5, 5, 5, 5, 5, 5, 4, 5, 4, 3, 3, 5, 5, 5, 4, 3, 5, 5, 5, 4, 3, 1, 4, 2, 5, 5, 5, 1, 5, 4, 3, 4, 4, 2, 5, 3, 4, 2, 5, 5, 4, 3, 2, 5, 5, 5, 5, 1, 5, 1, 4, 4, 4, 5, 3, 5, 4, 5, 4, 5, 5, 2, 5, 5, 5, 4, 3, 3, 5, 5, 5, 5, 4, 3, 4, 5, 4, 4, 5, 4, 5, 5, 5, 5, 1, 5, 4, 5, 5, 5, 3, 5, 3, 5, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 5, 2, 5, 4, 5, 3, 5, 4, 5, 4, 4, 4, 2, 5, 2, 5, 5, 4, 1, 5, 5, 5, 3, 5, 4, 5, 3, 4, 4, 5, 5, 5, 5, 5, 4, 3, 3, 4, 5, 4, 4, 3, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 2, 5, 5, 4, 3, 3, 5, 5, 3, 5, 5, 5, 4, 4, 5, 4, 5, 5, 4, 5, 4, 5, 4, 1, 4, 4, 5, 4, 5, 1, 4, 4, 5, 4, 5, 4, 4, 5, 5, 5, 5, 5, 3, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 4, 4, 3, 5, 5, 5, 5, 5, 5, 4, 4, 4, 5, 5, 5, 4, 4, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 4, 4, 4, 5, 5, 5, 5, 5, 4, 2, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 4, 4, 5, 4, 5, 4, 4, 5, 4, 2, 4, 5, 5, 5, 5, 5, 5, 5, 4, 4, 3, 3, 5, 4, 5, 5, 5, 5, 4, 3, 4, 5, 5, 4, 3, 4, 4, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5, 5, 5, 4, 5, 4, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 4, 3, 4, 3, 4, 3, 1, 5, 5, 4, 5, 4, 5, 5, 3, 5, 2, 2, 4, 4, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 5, 5, 5, 5, 5, 1, 5, 5, 3, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 4, 5, 4, 3, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 4, 5, 5, 5, 4, 5, 5, 3, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 2, 5, 5, 4, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 4, 5, 2, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 5, 5, 5, 5, 4, 3, 5, 5, 4, 3, 5, 5, 5, 5, 4, 5, 5, 5, 3, 5, 5, 4, 5, 4, 5, 5, 2, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 3, 5, 4, 5, 3, 2, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 4, 5, 5, 5, 4, 4, 2, 4, 5, 5, 4, 5, 5, 4, 5, 3, 5, 5, 5, 5, 5, 2, 5, 4, 4, 4, 5, 4, 5, 4, 5, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 5, 5, 5, 4, 3, 5, 4, 2, 5, 4, 5, 5, 5, 3, 1, 5, 3, 5, 4, 5, 5, 4, 4, 5, 3, 5, 5, 5, 5, 3, 2, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 3, 5, 5, 4, 5, 4, 4, 4, 3, 2, 5, 5, 5, 5, 2, 5, 4, 4, 5, 2, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 1, 5, 5, 2, 5, 5, 5, 5, 5, 3, 5, 4, 5, 1, 5, 5, 4, 2, 5, 1, 5, 5, 4, 4, 2, 5, 3, 5, 3, 3, 5, 5, 5, 5, 1, 5, 3, 1, 4, 5, 4, 4, 5, 5, 3, 1, 5, 5, 5, 2, 5, 4, 5, 3, 5, 5, 4, 5, 5, 4, 3, 2, 5, 1, 2, 5, 5, 2, 5, 1, 4, 1, 2, 5, 5, 5, 5, 4, 5, 3, 3, 5, 4, 5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 5, 3, 5, 4, 5, 4, 4, 1, 5, 5, 5, 3, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 5, 5, 2, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 3, 5, 4, 5, 4, 5, 5, 4, 4, 5, 5, 1, 4, 5, 5, 2, 4, 3, 4, 5, 5, 3, 5, 5, 5, 5, 4, 1, 3, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 3, 5, 5, 5, 5, 2, 5, 5, 4, 5, 3, 5, 5, 5, 5, 5, 1, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 1, 5, 4, 1, 4, 3, 4, 5, 5, 3, 4, 4, 3, 5, 4, 5, 5, 4, 5, 4, 1, 4, 5, 3, 4, 5, 5, 5, 4, 5, 3, 5, 4, 5, 4, 5, 4, 4, 4, 4, 5, 5, 4, 4, 1, 4, 5, 5, 5, 4, 5, 5, 4, 3, 5, 5, 4, 3, 5, 5, 5, 5, 4, 4, 5, 5, 4, 4, 5, 2, 5, 5, 4, 4, 5, 3, 5, 4, 5, 5, 5, 5, 4, 5, 4, 5, 3, 5, 4, 5, 5, 4, 5, 5, 5, 3, 5, 2, 3, 5, 5, 5, 1, 5, 4, 5, 1, 5, 3, 5, 5, 5, 5, 1, 5, 4, 5, 3, 5, 4, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 3, 4, 4, 5, 1, 5, 5, 4, 4, 5, 3, 5, 2, 5, 4, 5, 5, 5, 5, 5, 3, 1, 5, 1, 5, 4, 4, 5, 5, 5, 4, 5, 5, 2, 4, 4, 5, 2, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 3, 1, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 1, 5, 5, 4, 5, 5, 4, 5, 5, 5, 3, 5, 5, 3, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 4, 5, 4, 5, 5, 5, 4, 5, 3, 3, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 3, 4, 5, 3, 5, 4, 5, 5, 5, 5, 3, 5, 5, 5, 5, 4, 5, 4, 5, 5, 4, 5, 5, 5, 5, 2, 5, 5, 5, 4, 2, 4, 5, 5, 5, 3, 5, 5, 3, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 1, 5, 4, 4, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 1, 5, 4, 4, 3, 5, 3, 4, 5, 4, 1, 4, 5, 5, 4, 5, 5, 4, 5, 4, 5, 5, 4, 4, 4, 4, 1, 3, 4, 3, 5, 5, 5, 4, 5, 5, 4, 4, 5, 3, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 4, 5, 4, 4, 3, 5, 5, 2, 5, 5, 5, 4, 5, 4, 5, 1, 1, 5, 5, 1, 1, 5, 5, 5, 5, 5, 5, 3, 5, 4, 5, 3, 5, 5, 5, 5, 5, 4, 5, 5, 3, 4, 4, 5, 3, 5, 4, 4, 5, 5, 5, 1, 4, 3, 5, 4, 4, 4, 5, 5, 4, 5, 2, 5, 4, 4, 5, 5, 5, 1, 5, 4, 5, 3, 4, 4, 5, 4, 5, 5, 5, 4, 1, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 3, 4, 4, 5, 3, 3, 4, 1, 4, 5, 3, 4, 3, 4, 5, 3, 4, 5, 5, 3, 5, 3, 5, 5, 5, 5, 4, 5, 5, 5, 5, 3, 2, 4, 5, 5, 4, 5, 5, 3, 5, 5, 3, 5, 5, 4, 5, 5, 4, 3, 4, 5, 3, 5, 5, 1, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 4, 4, 5, 4, 5, 4, 5, 5, 4, 5, 5, 4, 5, 4, 1, 5, 5, 4, 4, 5, 5, 4, 5, 5, 4, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 2, 4, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "\n",
        "rms = sqrt(mean_squared_error(y_actual, y_predicted, squared=False))\n",
        "mae = mean_absolute_error(y_actual, y_predicted)\n",
        "\n",
        "print(\"rms \", rms)\n",
        "print(\"mae \", mae)"
      ],
      "metadata": {
        "id": "tg2dd34NawrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92633ac6-b11d-43a2-e403-397b19ffcbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rms  1.0531161619882878\n",
            "mae  0.7004\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries"
      ],
      "metadata": {
        "id": "Tg5nicD08lZQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10VqEhMLiUZC",
        "outputId": "9c534ffb-6ce7-48cb-f37b-c64239191938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/111.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install ijson --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy8i6upqtppx",
        "outputId": "91fea07b-fffc-4e87-cad4-454634c45276"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.23.5)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O10SAIZ8nAZg",
        "outputId": "93414010-3306-46fd-da27-69b689f15548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m61.4/86.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install -U sentence-transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPjDAC6wiZNi",
        "outputId": "4c04a8be-1ea7-48a7-e107-b3581ce8e8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mount the google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2r2XsRoDtrrT"
      },
      "outputs": [],
      "source": [
        "#import required libraries\n",
        "\n",
        "import ijson\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, T5ForConditionalGeneration, T5Tokenizer, T5Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rank_bm25 import BM25Okapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hYLoexvNL0m"
      },
      "outputs": [],
      "source": [
        "#base path where all project files are stored\n",
        "base_path = \"drive/MyDrive/CS646\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ1i--loniAn"
      },
      "outputs": [],
      "source": [
        "# This functions creates clusters for a given user profile. It puts reviews with same rating in a single cluster\n",
        "\n",
        "def get_clusters_for_user(user_profiles):\n",
        "    clusters = {}\n",
        "    clusters['1'] = []\n",
        "    clusters['2'] = []\n",
        "    clusters['3'] = []\n",
        "    clusters['4'] = []\n",
        "    clusters['5'] = []\n",
        "\n",
        "    for profile in user_profiles:\n",
        "        text = profile.get('text')\n",
        "        score = profile.get('score')\n",
        "        clusters[score].append(text)\n",
        "\n",
        "    return clusters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This function will return top 1 review from the user profile, using the BM25 similarity scores\n",
        "\n",
        "def get_bm25_top1(user_profiles, query):\n",
        "    clusters = {}\n",
        "    clusters['1'] = []\n",
        "    clusters['2'] = []\n",
        "    clusters['3'] = []\n",
        "    clusters['4'] = []\n",
        "    clusters['5'] = []\n",
        "    corpus = {}\n",
        "\n",
        "    max_score = 0\n",
        "    output_score = 0\n",
        "    output_review = \"\"\n",
        "\n",
        "    for profile in user_profiles:\n",
        "        text = profile.get('text')\n",
        "        score = profile.get('score')\n",
        "        clusters[score].append(text)\n",
        "\n",
        "        tokenized_corpus = [text.split(\" \")]\n",
        "        bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "        tokenized_query = query.split(\" \")\n",
        "\n",
        "        doc_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "        if doc_scores[0] > max_score:\n",
        "            max_score = doc_scores[0]\n",
        "            output_score = score\n",
        "            output_review = text\n",
        "\n",
        "    return output_score, output_review"
      ],
      "metadata": {
        "id": "U9uT5--xm3kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1iF7s5ilWdY"
      },
      "outputs": [],
      "source": [
        "# Generate the prompt from the reviews\n",
        "\n",
        "def generate_llm_input(input, top_k_reviews):\n",
        "  prompt = \"\"\n",
        "  for score,review in top_k_reviews.items():\n",
        "    prompt += str(score) + \" is the score for \" + '\"' + review + '\"' + \", and \"\n",
        "\n",
        "  prompt = prompt[:-6]\n",
        "  prompt += input\n",
        "\n",
        "  # print(prompt)\n",
        "\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The model to find embedding for a text\n",
        "\n",
        "%%capture\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "oXu7hTFwm871"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQxwR12Zptoq"
      },
      "outputs": [],
      "source": [
        "# get language model score for the given input review and existing relevant reviews\n",
        "\n",
        "def get_language_model_score(input, top_k_reviews):\n",
        "  model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "\n",
        "  prompt = generate_llm_input(input, top_k_reviews)\n",
        "  # print(\"prompt is :\" + prompt)\n",
        "\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "  outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "  rating = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "  return rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzVYh_QhbHtK"
      },
      "outputs": [],
      "source": [
        "# predict the ratings on the validation data\n",
        "\n",
        "def val(start_index, end_index):\n",
        "    val_ratings = {}\n",
        "    count = 0\n",
        "    iterated = 0\n",
        "    invalid_ratings = 0\n",
        "    with open(base_path + '/dev_questions.json', 'r') as file:\n",
        "        parser = ijson.items(file, 'item')\n",
        "        for item in parser:\n",
        "            count += 1\n",
        "            if count<start_index or count>end_index:\n",
        "                continue\n",
        "            user_id = item.get('id')\n",
        "            user_profiles = item.get('profile')\n",
        "            input = item.get('input')\n",
        "\n",
        "            test_review = input.split(':')[1].strip()\n",
        "\n",
        "            output_score, output_review = get_bm25_top1(user_profiles, test_review)\n",
        "\n",
        "            # here k = 1\n",
        "            top_k_reviews = {output_score: output_review}\n",
        "\n",
        "            rating = get_language_model_score(input, top_k_reviews)\n",
        "            rating = rating[0]\n",
        "            if rating not in ('1', '2', '3', '4', '5'):\n",
        "                rating = 5\n",
        "                invalid_ratings += 1\n",
        "\n",
        "            val_ratings[user_id] = rating\n",
        "            # print(\"rating is \" + rating)\n",
        "\n",
        "\n",
        "            iterated += 1\n",
        "            if iterated%100 == 0:\n",
        "                print(\"iterated: \" + str(iterated))\n",
        "\n",
        "    return val_ratings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EYyh6tJi0kjh"
      },
      "outputs": [],
      "source": [
        "# Find the predictions\n",
        "\n",
        "val_ratings = val(1,2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWWGGmJ3Pnoz"
      },
      "outputs": [],
      "source": [
        "# Storing the predictions in a csv file\n",
        "\n",
        "df = pd.DataFrame(val_ratings.items(), columns=['id', 'rating'])\n",
        "df.head(10)\n",
        "df.to_csv(base_path + '/val_ratings_bm25.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT5mfGwmFFgT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics Calculations"
      ],
      "metadata": {
        "id": "qg3AbUMHpAb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, we fetch the predictions of our model\n",
        "\n",
        "y_predicted = []\n",
        "\n",
        "filenames = ['val_ratings_bm25.csv']\n",
        "\n",
        "for filename in filenames:\n",
        "    filepath = base_path + '/' + filename\n",
        "    with open(filepath, 'r') as f:\n",
        "        count = 0\n",
        "        for line in f:\n",
        "            if count != 0:\n",
        "                y_predicted.append(int(line.split(',')[2]))\n",
        "            count += 1"
      ],
      "metadata": {
        "id": "EAZ1h-Vfphyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXUjnFFdpkI2",
        "outputId": "f3e443d3-190c-44a5-95c7-36d85a3e62ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWC3WL6Jnzo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ff8a47-95d3-4fc7-d1f2-5fe6db793c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_actual  [2, 5, 5, 1, 5, 3, 4, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 3, 5, 4, 5, 5, 4, 5, 4, 2, 3, 5, 2, 4, 5, 4, 3, 5, 5, 5, 5, 5, 4, 4, 1, 5, 5, 4, 5, 4, 5, 4, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 4, 5, 4, 1, 4, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 5, 5, 1, 5, 3, 3, 4, 5, 4, 4, 3, 4, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5, 5, 4, 5, 4, 2, 5, 5, 4, 5, 4, 5, 5, 5, 4, 5, 4, 5, 3, 4, 3, 3, 5, 5, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 3, 4, 4, 5, 5, 3, 5, 4, 5, 5, 4, 5, 5, 5, 5, 5, 5, 3, 1, 5, 5, 5, 1, 5, 5, 5, 4, 4, 3, 5, 5, 4, 4, 1, 4, 3, 5, 3, 2, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 3, 5, 4, 2, 4, 4, 4, 1, 5, 5, 5, 4, 5, 4, 5, 5, 2, 5, 3, 4, 5, 5, 4, 5, 3, 5, 5, 1, 2, 5, 4, 3, 5, 2, 5, 2, 5, 5, 5, 4, 4, 4, 5, 4, 5, 5, 5, 5, 5, 2, 5, 5, 4, 5, 4, 5, 5, 4, 5, 5, 5, 4, 5, 4, 4, 5, 5, 1, 5, 4, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5, 4, 5, 4, 5, 5, 5, 3, 4, 4, 3, 4, 5, 4, 5, 5, 5, 1, 5, 1, 4, 3, 5, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 2, 5, 4, 5, 5, 5, 1, 5, 5, 5, 5, 1, 5, 5, 5, 4, 5, 5, 5, 5, 3, 5, 4, 1, 3, 4, 4, 5, 3, 5, 5, 5, 1, 5, 4, 5, 4, 4, 5, 2, 3, 4, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 2, 4, 4, 5, 5, 5, 4, 5, 5, 4, 4, 1, 4, 4, 5, 5, 4, 3, 5, 3, 5, 5, 5, 5, 5, 4, 3, 2, 5, 4, 2, 5, 5, 5, 2, 4, 4, 5, 2, 5, 5, 5, 4, 5, 4, 5, 5, 5, 5, 3, 4, 5, 5, 5, 3, 2, 4, 4, 5, 4, 4, 5, 5, 5, 4, 5, 4, 5, 4, 5, 5, 5, 5, 4, 5, 5, 3, 2, 5, 5, 5, 3, 5, 4, 4, 5, 3, 4, 5, 5, 5, 5, 4, 5, 5, 3, 4, 5, 5, 5, 5, 5, 4, 3, 5, 5, 5, 5, 1, 4, 5, 5, 5, 3, 5, 2, 3, 2, 5, 2, 5, 2, 4, 5, 5, 5, 5, 4, 1, 5, 5, 5, 3, 3, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 3, 5, 5, 2, 5, 5, 5, 5, 4, 5, 3, 4, 5, 1, 5, 4, 5, 4, 4, 4, 4, 5, 4, 4, 5, 5, 5, 5, 5, 5, 4, 5, 5, 3, 4, 3, 4, 5, 5, 5, 3, 5, 4, 5, 4, 3, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 3, 5, 5, 2, 2, 5, 5, 4, 2, 4, 4, 5, 3, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 2, 5, 5, 5, 4, 5, 4, 4, 5, 4, 4, 1, 5, 5, 5, 4, 5, 5, 5, 4, 4, 4, 5, 5, 5, 5, 4, 2, 4, 2, 1, 2, 5, 3, 4, 5, 4, 5, 5, 5, 4, 5, 2, 4, 2, 5, 5, 5, 5, 4, 3, 4, 5, 5, 2, 4, 4, 5, 4, 5, 4, 5, 5, 4, 5, 4, 5, 4, 1, 5, 5, 4, 3, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 2, 5, 4, 5, 3, 3, 5, 5, 5, 5, 3, 4, 5, 4, 3, 5, 5, 5, 5, 4, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 5, 5, 1, 3, 5, 5, 5, 5, 3, 5, 1, 4, 5, 5, 5, 3, 2, 5, 5, 5, 3, 2, 4, 4, 5, 1, 5, 3, 5, 4, 5, 5, 4, 5, 5, 5, 3, 4, 3, 5, 1, 5, 4, 4, 5, 5, 5, 3, 4, 5, 2, 5, 5, 5, 5, 5, 5, 5, 1, 5, 4, 5, 5, 4, 5, 4, 5, 5, 5, 5, 4, 2, 5, 4, 4, 3, 5, 1, 5, 4, 4, 5, 1, 5, 5, 5, 5, 5, 4, 5, 5, 3, 4, 5, 5, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 2, 5, 5, 5, 4, 5, 5, 1, 5, 4, 5, 5, 5, 5, 4, 4, 2, 4, 5, 4, 5, 5, 1, 5, 3, 4, 3, 1, 5, 5, 4, 5, 4, 5, 5, 4, 4, 5, 4, 4, 4, 5, 5, 5, 5, 5, 2, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 4, 5, 2, 4, 5, 5, 5, 4, 1, 3, 5, 5, 4, 2, 5, 5, 4, 5, 4, 5, 5, 4, 4, 4, 1, 5, 5, 3, 4, 5, 4, 4, 5, 5, 5, 5, 1, 4, 5, 4, 5, 5, 4, 5, 4, 5, 3, 5, 2, 5, 4, 4, 5, 5, 4, 5, 5, 5, 4, 5, 4, 1, 4, 5, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 5, 4, 5, 5, 1, 5, 4, 5, 2, 5, 3, 1, 3, 5, 4, 5, 5, 3, 2, 2, 5, 5, 5, 5, 1, 4, 5, 4, 4, 5, 5, 5, 1, 5, 3, 4, 5, 5, 5, 5, 5, 5, 4, 5, 4, 3, 3, 5, 5, 5, 4, 3, 5, 5, 5, 4, 3, 1, 4, 2, 5, 5, 5, 1, 5, 4, 3, 4, 4, 2, 5, 3, 4, 2, 5, 5, 4, 3, 2, 5, 5, 5, 5, 1, 5, 1, 4, 4, 4, 5, 3, 5, 4, 5, 4, 5, 5, 2, 5, 5, 5, 4, 3, 3, 5, 5, 5, 5, 4, 3, 4, 5, 4, 4, 5, 4, 5, 5, 5, 5, 1, 5, 4, 5, 5, 5, 3, 5, 3, 5, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 5, 2, 5, 4, 5, 3, 5, 4, 5, 4, 4, 4, 2, 5, 2, 5, 5, 4, 1, 5, 5, 5, 3, 5, 4, 5, 3, 4, 4, 5, 5, 5, 5, 5, 4, 3, 3, 4, 5, 4, 4, 3, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 2, 5, 5, 4, 3, 3, 5, 5, 3, 5, 5, 5, 4, 4, 5, 4, 5, 5, 4, 5, 4, 5, 4, 1, 4, 4, 5, 4, 5, 1, 4, 4, 5, 4, 5, 4, 4, 5, 5, 5, 5, 5, 3, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 4, 4, 3, 5, 5, 5, 5, 5, 5, 4, 4, 4, 5, 5, 5, 4, 4, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 4, 4, 4, 5, 5, 5, 5, 5, 4, 2, 5, 5, 5, 5, 4, 4, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 4, 4, 5, 4, 5, 4, 4, 5, 4, 2, 4, 5, 5, 5, 5, 5, 5, 5, 4, 4, 3, 3, 5, 4, 5, 5, 5, 5, 4, 3, 4, 5, 5, 4, 3, 4, 4, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5, 5, 5, 4, 5, 4, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 4, 3, 4, 3, 4, 3, 1, 5, 5, 4, 5, 4, 5, 5, 3, 5, 2, 2, 4, 4, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 5, 5, 5, 5, 5, 1, 5, 5, 3, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 4, 5, 4, 3, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 4, 5, 5, 5, 4, 5, 5, 3, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 2, 5, 5, 4, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 4, 5, 2, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 5, 5, 5, 5, 4, 3, 5, 5, 4, 3, 5, 5, 5, 5, 4, 5, 5, 5, 3, 5, 5, 4, 5, 4, 5, 5, 2, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 3, 5, 4, 5, 3, 2, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 4, 5, 5, 5, 4, 4, 2, 4, 5, 5, 4, 5, 5, 4, 5, 3, 5, 5, 5, 5, 5, 2, 5, 4, 4, 4, 5, 4, 5, 4, 5, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 5, 5, 5, 4, 3, 5, 4, 2, 5, 4, 5, 5, 5, 3, 1, 5, 3, 5, 4, 5, 5, 4, 4, 5, 3, 5, 5, 5, 5, 3, 2, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 3, 5, 5, 4, 5, 4, 4, 4, 3, 2, 5, 5, 5, 5, 2, 5, 4, 4, 5, 2, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 1, 5, 5, 2, 5, 5, 5, 5, 5, 3, 5, 4, 5, 1, 5, 5, 4, 2, 5, 1, 5, 5, 4, 4, 2, 5, 3, 5, 3, 3, 5, 5, 5, 5, 1, 5, 3, 1, 4, 5, 4, 4, 5, 5, 3, 1, 5, 5, 5, 2, 5, 4, 5, 3, 5, 5, 4, 5, 5, 4, 3, 2, 5, 1, 2, 5, 5, 2, 5, 1, 4, 1, 2, 5, 5, 5, 5, 4, 5, 3, 3, 5, 4, 5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 5, 3, 5, 4, 5, 4, 4, 1, 5, 5, 5, 3, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 5, 5, 2, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 3, 5, 4, 5, 4, 5, 5, 4, 4, 5, 5, 1, 4, 5, 5, 2, 4, 3, 4, 5, 5, 3, 5, 5, 5, 5, 4, 1, 3, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 3, 5, 5, 5, 5, 2, 5, 5, 4, 5, 3, 5, 5, 5, 5, 5, 1, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 1, 5, 4, 1, 4, 3, 4, 5, 5, 3, 4, 4, 3, 5, 4, 5, 5, 4, 5, 4, 1, 4, 5, 3, 4, 5, 5, 5, 4, 5, 3, 5, 4, 5, 4, 5, 4, 4, 4, 4, 5, 5, 4, 4, 1, 4, 5, 5, 5, 4, 5, 5, 4, 3, 5, 5, 4, 3, 5, 5, 5, 5, 4, 4, 5, 5, 4, 4, 5, 2, 5, 5, 4, 4, 5, 3, 5, 4, 5, 5, 5, 5, 4, 5, 4, 5, 3, 5, 4, 5, 5, 4, 5, 5, 5, 3, 5, 2, 3, 5, 5, 5, 1, 5, 4, 5, 1, 5, 3, 5, 5, 5, 5, 1, 5, 4, 5, 3, 5, 4, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 3, 4, 4, 5, 1, 5, 5, 4, 4, 5, 3, 5, 2, 5, 4, 5, 5, 5, 5, 5, 3, 1, 5, 1, 5, 4, 4, 5, 5, 5, 4, 5, 5, 2, 4, 4, 5, 2, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 3, 1, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 1, 5, 5, 4, 5, 5, 4, 5, 5, 5, 3, 5, 5, 3, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 4, 5, 4, 5, 5, 5, 4, 5, 3, 3, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 3, 4, 5, 3, 5, 4, 5, 5, 5, 5, 3, 5, 5, 5, 5, 4, 5, 4, 5, 5, 4, 5, 5, 5, 5, 2, 5, 5, 5, 4, 2, 4, 5, 5, 5, 3, 5, 5, 3, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 1, 5, 4, 4, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 1, 5, 4, 4, 3, 5, 3, 4, 5, 4, 1, 4, 5, 5, 4, 5, 5, 4, 5, 4, 5, 5, 4, 4, 4, 4, 1, 3, 4, 3, 5, 5, 5, 4, 5, 5, 4, 4, 5, 3, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 4, 5, 4, 4, 3, 5, 5, 2, 5, 5, 5, 4, 5, 4, 5, 1, 1, 5, 5, 1, 1, 5, 5, 5, 5, 5, 5, 3, 5, 4, 5, 3, 5, 5, 5, 5, 5, 4, 5, 5, 3, 4, 4, 5, 3, 5, 4, 4, 5, 5, 5, 1, 4, 3, 5, 4, 4, 4, 5, 5, 4, 5, 2, 5, 4, 4, 5, 5, 5, 1, 5, 4, 5, 3, 4, 4, 5, 4, 5, 5, 5, 4, 1, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 3, 4, 4, 5, 3, 3, 4, 1, 4, 5, 3, 4, 3, 4, 5, 3, 4, 5, 5, 3, 5, 3, 5, 5, 5, 5, 4, 5, 5, 5, 5, 3, 2, 4, 5, 5, 4, 5, 5, 3, 5, 5, 3, 5, 5, 4, 5, 5, 4, 3, 4, 5, 3, 5, 5, 1, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 4, 4, 5, 4, 5, 4, 5, 5, 4, 5, 5, 4, 5, 4, 1, 5, 5, 4, 4, 5, 5, 4, 5, 5, 4, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 2, 4, 4, 5]\n"
          ]
        }
      ],
      "source": [
        "# Here, we find the ground truth outputs\n",
        "\n",
        "import json\n",
        "\n",
        "y_actual = []\n",
        "with open(base_path + '/dev_outputs.json') as f:\n",
        "    d = json.load(f)\n",
        "    golds = d.get('golds')\n",
        "    for gold in golds:\n",
        "        y_actual.append(int(gold.get('output')))\n",
        "    print(\"y_actual \", y_actual)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we find the RMSE and MAE metrics\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "\n",
        "rms = sqrt(mean_squared_error(y_actual, y_predicted, squared=False))\n",
        "mae = mean_absolute_error(y_actual, y_predicted)\n",
        "\n",
        "print(\"rms \", rms)\n",
        "print(\"mae \", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s56nfR5fpE2-",
        "outputId": "6e46ccfb-e928-49fd-d80b-3b6d48bd7697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rms  1.0478540826397846\n",
            "mae  0.72\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}